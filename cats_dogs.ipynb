{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pung7XDsuNEh",
        "colab_type": "code",
        "outputId": "804f5fc2-58ac-4660-a6ad-923a164a500e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLWSBan93AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from os import listdir\n",
        "from PIL import ImageOps, Image\n",
        "from glob import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCNIxHK5dpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fonction d'entrainement\n",
        "def training(model, train_dataloader, valid_dataloader=None, epoch=5, learning_rate=0.1, use_gpu=False):\n",
        "  \n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "  \n",
        "  train_accu = []\n",
        "  train_losses = []\n",
        "  \n",
        "  if valid_dataloader:\n",
        "    val_accu = []\n",
        "    val_loss = []\n",
        "    \n",
        "  for i in range(epoch):\n",
        "    model.train()\n",
        "    \n",
        "    print('Starting epoch number {} on {} ...'.format(i+1, epoch))\n",
        "    \n",
        "    true = []\n",
        "    pred = []\n",
        "    train_loss = []\n",
        "    len_train = len(train_dataloader)\n",
        "    for ind, batch in enumerate(train_dataloader):\n",
        "      print('\\rBatch : {}/{}'.format(ind+1, len_train), end='')\n",
        "      inputs, targets = batch\n",
        "      \n",
        "      # Aller le GPU, fais ton taff\n",
        "      if use_gpu:\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "        \n",
        "      outputs = model(inputs)\n",
        "      \n",
        "      loss = criterion(outputs, targets)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "      predictions = outputs.max(dim=1)[1]\n",
        "      \n",
        "      train_loss.append(loss.item())\n",
        "      true.extend(targets.data.cpu().numpy().tolist())\n",
        "      pred.extend(predictions.data.cpu().numpy().tolist())\n",
        "    \n",
        "    accu_score = accuracy_score(true, pred) * 100\n",
        "    loss_score = sum(train_loss) / len(train_loss)\n",
        "    \n",
        "    print('\\nTrain score : Accuracy = {:.2f} - Loss = {:.2f}'.format(accu_score, loss_score), end='')\n",
        "    \n",
        "    \n",
        "    train_accu.append(accuracy_score(true, pred) * 100)\n",
        "    train_losses.append(loss_score)\n",
        "      \n",
        "    if valid_dataloader:\n",
        "      vaccu, vloss = validating(model, valid_dataloader, use_gpu)\n",
        "      print(' | Validation score : Accuracy = {:.2f} - Loss = {:.2f}'.format(vaccu, vloss))\n",
        "      val_accu.append(vaccu)\n",
        "      val_loss.append(vloss)\n",
        "    else:\n",
        "      print()\n",
        "  \n",
        "  if valid_dataloader:\n",
        "    return train_accu, train_losses, val_accu, val_loss\n",
        "  else:\n",
        "    return train_accu, train_loss\n",
        "  \n",
        "  return None, None\n",
        "  \n",
        "\n",
        "# Fonction de validation\n",
        "def validating(model, dataloader, use_gpu=False):\n",
        "  true =[]\n",
        "  pred = []\n",
        "  val_loss = []\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "  model.eval()\n",
        "\n",
        "  for batch in dataloader:\n",
        "\n",
        "    inputs, targets = batch\n",
        "\n",
        "    # On envoit les données au GPU pour le traitement\n",
        "    if use_gpu:\n",
        "      inputs = inputs.cuda()\n",
        "      targets = targets.cuda()\n",
        "    \n",
        "    outputs = model(inputs)\n",
        "\n",
        "    predictions = outputs.max(dim=1)[1]\n",
        "\n",
        "    val_loss.append(criterion(outputs, targets).item())\n",
        "    true.extend(targets.data.cpu().numpy().tolist())\n",
        "    pred.extend(predictions.data.cpu().numpy().tolist())\n",
        "  \n",
        "  accu_score = accuracy_score(true, pred) * 100\n",
        "  loss_score = sum(val_loss) / len(val_loss)\n",
        "  return accu_score, loss_score\n",
        "\n",
        "\n",
        "# Fonction de prédiction\n",
        "#def predict(model, sentence, vocab, max_len):\n",
        "#  tokens = word_tokenize(sentence)\n",
        "#  X_test_len = len(tokens)\n",
        "#  X_test = prepareData(tokens, vocab, max_len)\n",
        "#  X_test = torch.LongTensor(X_test).cuda()\n",
        "#  X_test_len = torch.FloatTensor(X_test_len).cuda()\n",
        "#  output = model(X_test, X_test_len)\n",
        "#  prediction = output.max(dim=1)[1]\n",
        "#  print(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--yWNVSEXyUo",
        "colab_type": "code",
        "outputId": "5ea30083-0fca-4cc2-f289-9bccc46b1de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Cellule pour éviter les doublons dans les positifs et négatifs.\n",
        "# Lancer la cellule 2 fois pour que le calcul se fasse\n",
        "\n",
        "files_pos = [f for f in listdir(\"/content/gdrive/My Drive/datas/pixabay/dogs/1\")]\n",
        "files_neg = [f for f in listdir(\"/content/gdrive/My Drive/datas/pixabay/dogs/0\")]\n",
        "\n",
        "cnt = 0\n",
        "for f in files_pos:\n",
        "  if f in files_neg:\n",
        "    cnt += 1\n",
        "    \n",
        "print(cnt)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emw2Tfr0VkDJ",
        "colab_type": "text"
      },
      "source": [
        "Dans ce cadre précis il faut ajouter du padding à chaque image. Pour se faire, nous devons rechercher la largeur max et la longueur max."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX7-e7L-6Lsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AddPadding:\n",
        "  def __init__(self, maxHeight, maxWidth):\n",
        "    self.maxHeight = maxHeight\n",
        "    self.maxWidth = maxWidth\n",
        "\n",
        "  def __call__(self, img):\n",
        "    # Utilisation du code https://discuss.pytorch.org/t/add-padding-to-images/24309/3\n",
        "    delta_width = self.maxWidth - img.size[0]\n",
        "    delta_height = self.maxHeight - img.size[1]\n",
        "    pad_width = delta_width //2\n",
        "    pad_height = delta_height //2\n",
        "    padding = (pad_width,pad_height,delta_width-pad_width,delta_height-pad_height)\n",
        "    return ImageOps.expand(img, padding)\n",
        "\n",
        "def create_dataloader(dataset):\n",
        "    train_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=128,\n",
        "        num_workers=0,\n",
        "        shuffle=True\n",
        "    )\n",
        "    return train_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WsTrb1U9rgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# On charge les dataloaders (en supprimant les images précédentes pour libérer l'espace)\n",
        "img_path = \"/content/gdrive/My Drive/datas/pixabay/dogs/\"\n",
        "maxH = 340\n",
        "maxW = 1162\n",
        "all_transforms = transforms.Compose(\n",
        "    [\n",
        "     AddPadding(maxH, maxW),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")\n",
        "train_dataset = torchvision.datasets.ImageFolder(\n",
        "    root=img_path,\n",
        "    transform=all_transforms\n",
        ")\n",
        "\n",
        "# Dataloader\n",
        "data_loader = create_dataloader(train_dataset)\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# La classification se fait sur 2 classes uniquement\n",
        "model.fc = nn.Linear(512, 2)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVCvJlgqpdmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training(model, data_loader, use_gpu=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}